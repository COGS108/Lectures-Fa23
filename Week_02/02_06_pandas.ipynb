{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "- `pandas`\n",
    "- Where to find data?\n",
    "   - Web Scraping & APIs\n",
    "   \n",
    "   \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/COGS108/Lectures-Fa23/blob/main/Week_02/02_06_pandas.ipynb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/COGS108/Lectures-Wi22/main/02_python/img/pandas.png\" alt=\"pandas\" width=\"600px\">\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is Python library for managing heterogenous data.\n",
    "\n",
    "At its core, Pandas is used for the **DataFrame** object, which is:\n",
    "- a data structure for labeled rows and columns of data\n",
    "- associated methods and utilities for working with data.\n",
    "- each column contains a `pandas` **Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a csv file of data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/COGS108/Lectures-Wi22/main/02_python/data/my_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out a few rows of the dataframe\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrame:\n",
    "- Index for each row\n",
    "- Column name for each column (Series)\n",
    "- Stores heterogenous types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing (Indexing): select a Series (column) using its name\n",
    "df.loc[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3:8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'last_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing: select a row & column with 'loc'\n",
    "df.loc[4, 'age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clicker Question #1\n",
    "\n",
    "What would be the output of `df['age'] > 10`?\n",
    "\n",
    "- A) subset of `df` including only rows of individuals older than 10\n",
    "- B) a Boolean with `True` for rows where age is greater than 10 and `False` otherwise\n",
    "- C) `id`s of rows where observations are greater than 10 \n",
    "- D) an error\n",
    "- E) I'm super lost\n",
    "\n",
    "\n",
    "https://forms.gle/BYRApB9gMcFP4zKm6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] > 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get subset\n",
    "df.loc[ (df['age'] > 60), 'first_name':'age'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('score < 0')\n",
    "# loc[:,'first_name':'score']\n",
    "# then show how to make it neater on multiple lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( df\n",
    " .set_index('first_name')\n",
    "# .loc['Andrea'] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how large our dataframe is\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what columns we have in our DataFrame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes of our variables\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "- quantitative (numbers)\n",
    "- qualitative (categorical)\n",
    "- basic descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking categorical data\n",
    "df['first_name'].value_counts()\n",
    "#[4:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a particular descriptive statistic\n",
    "df[['id','age', 'value']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe a particular column\n",
    "df['value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics of all numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clicker Question #2\n",
    "\n",
    "What's the average (mean) age of the individuals in this dataset?\n",
    "\n",
    "- A) 14\n",
    "- B) 46\n",
    "- C) 28730\n",
    "- D) NA\n",
    "- E) I'm super lost/unsure\n",
    "\n",
    "https://forms.gle/FQWVCDabmwgKQF796\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pandas`: Common Manipulations\n",
    "\n",
    "You'll want to be *very* familiar with a few common data manipulations when wrangling data, each of which is described below:\n",
    "\n",
    "Manipulation | Description\n",
    "-------|------------\n",
    "**select** | select which columns to include in dataset\n",
    "**filter** | filter dataset to only include specified rows\n",
    "**mutate** | add a new column based on values in other columns\n",
    "**groupby** | group values to apply a function within the specified groups\n",
    "**summarize** | calculate specified summary metric of a specified variable\n",
    "**arrange** | sort rows ascending or descending order of a specified column\n",
    "**merge** | join separate datasets into a single dataset based on a common column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting & Dropping Columns\n",
    "\n",
    "- include subset of columns of larger data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which columns to include\n",
    "select_df = df[['id', 'age', 'score', 'value']]\n",
    "select_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop things we don't want\n",
    "df.drop(labels=['first_name','age'], axis='columns').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop things we don't want\n",
    "df.drop(labels=[0,2,6], axis='rows').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data (slicing)\n",
    "\n",
    "- include a subset (slice) of rows from larger data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have any data from people below the age of 18\n",
    "sum(df['age'] < 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['age'] < 18 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only participants who are 18 or older\n",
    "print('before filtering', df.shape)\n",
    "df2 = df[ df['age'] >= 18 ]\n",
    "print('after filtering', df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedf = pd.util.testing.makeTimeDataFrame()\n",
    "timedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedf.loc['2000-01-10':'2000-01-17']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data (NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df['value'].hasnans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note in class\n",
    "# can operate on entire dataframe\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note in class\n",
    "# equivalent\n",
    "df.loc[ df['value'].isna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isnull().sum(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the missing values\n",
    "df[df['value'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data - NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with null values: Drop rows with missing data\n",
    "print(df.shape)\n",
    "df2 = df.dropna()\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.fillna(value=100)\n",
    "df2.iloc[15:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.fillna(method='ffill')\n",
    "df2.iloc[15:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding and Dealing with Bad Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the properties of specific columns\n",
    "df['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for how many values have a -1 value in 'score'\n",
    "sum(df['score'] == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to above\n",
    "df[df.score<0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the plot of the data for score to see the distribution\n",
    "df['score'].plot(kind='hist', bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row with -1 value in 'score'\n",
    "print(df.shape)\n",
    "df2 = df[df['score'] != -1]\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new columns (mutating)\n",
    "\n",
    "- `assign` can be very helpful in adding a new column\n",
    "- lambda functions can be used to carry out calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert age in years to age in (approximate) days\n",
    "df = df.assign(age_days = df['age'] * 365)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_months'] = df['age'] * 12\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping & summarizing\n",
    "\n",
    "- group by a particular variable\n",
    "- calculate summary statistics/metrics within group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caclculate average within each age\n",
    "df.groupby('first_name').age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Rows (arrange)\n",
    "\n",
    "- specify order in which to display rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by values in age\n",
    "df = df.sort_values(by = ['age'],ascending=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining datasets\n",
    "![](https://raw.githubusercontent.com/COGS108/Lectures-Wi22/main/02_python/img/join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create two DataFrames\n",
    "left = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})    \n",
    "right = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': np.random.randn(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left.merge(right, on='key' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to above\n",
    "# inner merge by default\n",
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "pd.merge(left, right, on='key', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right merge\n",
    "pd.merge(left, right, on='key', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left merge\n",
    "pd.merge(left, right, on='key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join\n",
    "pd.merge(left, right, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clicker Question #3\n",
    "\n",
    "If table A had 5 rows and table B had 5 rows and 3 of those rows in each table were from the same observations present in the *other* table, how many rows would be present if an **inner merge** were carried out?\n",
    "\n",
    "- A) 3\n",
    "- B) 5\n",
    "- C) 10\n",
    "- D) 13\n",
    "- E) Totally unsure\n",
    "\n",
    "#### clicker Question #4\n",
    "\n",
    "If table A had 5 rows and table B had 5 rows and 3 of those rows in each table were from the same observations present in the *other* table, how many rows would be present if a **left merge** were carried out?\n",
    "\n",
    "- A) 3\n",
    "- B) 5\n",
    "- C) 10\n",
    "- D) 13\n",
    "- E) Totally unsure\n",
    "\n",
    "\n",
    "https://forms.gle/1nGZQYVTb7dMWBod9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data\n",
    "\n",
    "- We'll have a whole lecture (or two) on visualization\n",
    "- For now, we'll just look at one uniquely-pandas approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all numerical columns, and their interactions\n",
    "pd.plotting.scatter_matrix(df[['age', 'score', 'value']], figsize=[12, 12], marker=12);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Program Interface (APIs)\n",
    "\n",
    "- APIs are basically a way for software to talk to software \n",
    "    - They are an interface into an application / website / database designed for computers / software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on APIs:\n",
    "- Follow API guidelines! \n",
    "- These guidelines typically specify the number / rate / size of requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github API\n",
    "\n",
    "You can access the github api with the following API. Just added specifiers for what you are looking for. \n",
    "\n",
    "https://api.github.com/\n",
    "\n",
    "For example, the following URL will search for the user 'ShanEllis'\n",
    "\n",
    "https://api.github.com/users/shanellis\n",
    "\n",
    "<center>\n",
    "<img src=\"img/github.png\" alt=\"sql\" height=\"100\" width=\"100\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting Web Pages from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The requests module allows you to send URL requests from python\n",
    "import requests  \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request data from the Github API on a particular user\n",
    "page = requests.get('https://api.github.com/users/jasongfleischer')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The content we get back is organized... but not easy to read\n",
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clicker Question #5\n",
    "\n",
    "What type/format of output is this?\n",
    "\n",
    "- A) CSV\n",
    "- B) XML\n",
    "- C) JSON\n",
    "- D) API\n",
    "- E) I'm super lost\n",
    "\n",
    "https://forms.gle/hnB8aEoSAL5UWJRN9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can read in the json data with pandas\n",
    "# .decode('ascii') may or may not be necessary... when content is type b'' it is needed\n",
    "git_data = pd.read_json(page.content.decode('ascii'), typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the pandas series object full of data\n",
    "git_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authorized Access - OAuth\n",
    "\n",
    "Open Authorization is a protocol to authorize access (of a user / application) to an API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OAuth provides a secure way to 'log-in' without using account names and passwords. \n",
    "\n",
    "It is effectively a set of keys, and passwords you can use to access APIs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping vs. APIs\n",
    "\n",
    "Web scraping and APIs are different approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- APIs are an interface to interact with an application, designed for programmatic use\n",
    "    - They allow systematic, controlled access to (for example) and applications database\n",
    "    - They typically return structured (friendly) data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Web scraping (typically) involves navigating through the internet, programmatically following an architecture built for humans\n",
    "    - This can be hard to systematize, being dependent on the idiosyncracies of a web page, at the time you request it\n",
    "    - This typically returns relatively unstructured data\n",
    "    - This entails much more wrangling of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to Find Data?\n",
    "\n",
    "* [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets/blob/master/README.rst)\n",
    "* [Data.gov](https://catalog.data.gov/dataset)\n",
    "* [Data Is Plural](https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0)\n",
    "* [UCSD Datasets](https://ucsd.libguides.com/data-statistics/home)\n",
    "* [Datasets | Deep Learning](http://deeplearning.net/datasets/)\n",
    "* [Stanford | Social Science Data Collection](https://data.stanford.edu/)\n",
    "* [Eviction Lab (email required)](https://evictionlab.org/get-the-data/)\n",
    "* [San Diego Data](https://data.sandiego.gov/)\n",
    "* [US Census](https://www.census.gov/)\n",
    "* [Open Climate Data](http://openclimatedata.net/)\n",
    "* [Data and Story Library](https://dasl.datadescription.com/datafiles/)\n",
    "* [UCSD behavioral mobile data](http://extrasensory.ucsd.edu/)\n",
    "* [Kaggle](https://www.kaggle.com/)\n",
    "* [FiveThirtyEight](https://data.fivethirtyeight.com/)\n",
    "* [data.world](https://data.world/)\n",
    "* [Free Datasets - R and Data Mining ](http://www.rdatamining.com/resources/data)\n",
    "* [Data Sources for Cool Data Science Projects](https://blog.thedataincubator.com/2014/10/data-sources-for-cool-data-science-projects-part-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Working with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science is Ad-Hoc\n",
    "\n",
    "- It is part of the job description to put things together that were not designed to go together.\n",
    "- We do not have universal solutions, but haphazard, idiosyncratic systems, for data collection, storage and analysis.\n",
    "- Data is everywhere. But relatively little of it was collected *as data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection, Curation, and Storage are Difficult\n",
    "\n",
    "- It can be difficult to choose broadly useful standards\n",
    "- Take time to think about your data, and how you will load, store, organize and save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is Inherently Noisy\n",
    "\n",
    "- We live in a messy, noisy, world, with messy, noisy, people, using messy, noisy instruments.\n",
    "- There is no perfect data. \n",
    "    - There is better / or worse data, given the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Objectives\n",
    "\n",
    "- Humans and computers are different.\n",
    "- We interact with '*data*' in different ways.\n",
    "- This underlies many aspects of data wrangling\n",
    "    - The 'friendliness' of data types / files\n",
    "    - The difference between web scraping and APIs\n",
    "    - A disconnect between data in the real world, and data we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So... What to do?\n",
    "\n",
    "- Think about how your data are stored & its structure?\n",
    "- Look at your data before you anayze it\n",
    "    - are there missing values? \n",
    "    - outlier values? \n",
    "- Are your data trustworthy? \n",
    "    - source?\n",
    "    - how was it generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Recommendations\n",
    "\n",
    "- Prioritize using well structured, common, open file types\n",
    "    - Take advantage of existing tools to deal with these files (numpy, pandas, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look into, and then follow, common conventions\n",
    "    - Minimize custom objects, workflows and data files \n",
    "- Look for APIs. Ask if they are available.\n",
    "    - Acknowledge that web scraping and/or wrangling unstructured data are complex / long tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Think about data flow from the beginning. Organize your data pipeline, consider the 'wrangling' aspects throughout\n",
    "    - Set yourself up with well organized, labelled approach to your data\n",
    "    - Think about when and how you might want/need to save out intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
